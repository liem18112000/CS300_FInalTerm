# -*- coding: utf-8 -*-
"""FashionMNIST_TPU.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vi5zIapn3ZdPZ4L6HxvHT20QeW9yAo3J
"""

import tensorflow as tf
from tensorflow.keras.layers import *
from tensorflow.keras.models import Sequential as Base_Model
from tensorflow.keras.datasets import fashion_mnist as dataset
import os
from datetime import datetime
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

class ModelFactory(object):

    def createPretrainedModel(self, Pretrained_Model):

        pretrained_model = Pretrained_Model(
            input_shape=(224, 224, 3),
            include_top = False,
            weights='imagenet'
        )

        for layer in pretrained_model.layers:
            layer.trainable = False

        model = Base_Model([
            Input(shape=(28, 28, 1)),
            UpSampling3D(size=(8, 8, 3)),
            pretrained_model,
            Dropout(0.5),
            Flatten(),
            Dense(2048, activation='relu'),
            Dense(1024, activation='relu'),
            Dense(512, activation='relu'),
            Dense(256, activation='relu'),
            Dense(128, activation='relu'),
            Dense(10, activation='softmax'),
        ])

        model.summary()

        return model

    def createPlainModel(self):
        model = Base_Model([
            Flatten(input_shape=(28, 28)),
            Dense(512, activation='relu'),
            Dense(10, activation='softmax')
        ])

        model.summary()
        return model

    def createSimpleCNNModel(self):
        model = Base_Model([
            Input(shape=(28, 28, 1)),
            UpSampling3D(size=(1, 1, 3)),
            Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 3)),
            MaxPooling2D((2, 2)),
            Flatten(),
            Dense(512, activation='relu'),
            Dense(10, activation='softmax')
        ])

        model.summary()
        return model

    def createCNNModel_1(self):
        model = Base_Model([
            Input(shape=(28, 28, 1)),
            UpSampling3D(size=(1, 1, 3)),
            Conv2D(48, (5, 5), activation='relu',padding="same", input_shape=(28, 28, 3)),
            MaxPooling2D((2, 2), padding="same"),
            Conv2D(96, (5, 5), activation='relu', padding="same"),
            MaxPooling2D((2, 2), padding="same"),
            Conv2D(80, (5, 5), activation='relu', padding="same"),
            Conv2D(96, (5, 5), activation='relu', padding="same"),
            Flatten(),
            Dense(512, activation='relu'),
            Dense(10, activation='softmax')
        ])

        model.summary()
        return model

    def createCNNModel_2(self):
        model = Base_Model([
            Input(shape=(28, 28, 1)),
            UpSampling3D(size=(1, 1, 3)),
            Conv2D(48, (5, 5), activation='relu',padding="same", input_shape=(28, 28, 3)),
            MaxPooling2D((2, 2), padding="same"),
            Conv2D(80, (5, 5), activation='relu', padding="same"),
            MaxPooling2D((2, 2), padding="same"),
            Conv2D(64, (5, 5), activation='relu', padding="same"),
            Conv2D(80, (5, 5), activation='relu', padding="same"),
            Conv2D(96, (5, 5), activation='relu', padding="same"),
            Conv2D(96, (5, 5), activation='relu', padding="same"),
            Conv2D(64, (5, 5), activation='relu', padding="same"),
            Conv2D(80, (5, 5), activation='relu', padding="same"),
            Flatten(),
            Dense(512, activation='relu'),
            Dense(10, activation='softmax')
        ])

        model.summary()
        return model

def visualize_history(history):
    # summarize history for accuracy
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_accuracy'])
    plt.title('model accuracy')
    plt.ylabel('accuracy')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper left')
    plt.show()
    # summarize history for loss
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('model loss')
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper left')
    plt.show()

# Load Fashion MNIST datasets
(x_train, y_train), (x_test, y_test) = dataset.load_data()

# Expand dimensions of datasets
x_train_1, x_test_1 = np.expand_dims(x_train, axis = 3), np.expand_dims(x_test, axis = 3)  

# Rescale the images from [0,255] to the [0.0, 1.0] range.
x_train_1, x_test_1 = np.array(x_train, dtype=np.float32)/255.0, np.array(x_test, dtype=np.float32)/255.0
y_train_1, y_test_1 = tf.keras.utils.to_categorical(y_train, 10, dtype=np.uint8),tf.keras.utils.to_categorical(y_test, 10, dtype=np.uint8)

# Brief information of datasets
print("Shape of original training examples:", np.shape(x_train_1))
print("Shape of original test examples:", np.shape(x_test_1))
print("Shape of original training result:", np.shape(y_train_1))
print("Shape of original test result:", np.shape(y_test_1))

"""## Pretrained Model

### VGG19
"""

resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])
tf.config.experimental_connect_to_cluster(resolver)
tf.tpu.experimental.initialize_tpu_system(resolver)
strategy = tf.distribute.experimental.TPUStrategy(resolver)

from tensorflow.keras.applications import VGG19

with strategy.scope():
    factory = ModelFactory()

    model = factory.createPretrainedModel(VGG19)

    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    history = model.fit(
        x_train_1, y_train_1, 
        validation_data = (x_test_1, y_test_1),
        batch_size=2048, 
        epochs=50,
        callbacks = [
            tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, restore_best_weights = True),
            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights = True)
        ]
    )

model.evaluate(x_test_1, y_test_1, 1024)

visualize_history(history)

"""### ResNet152V2"""

resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])
tf.config.experimental_connect_to_cluster(resolver)
tf.tpu.experimental.initialize_tpu_system(resolver)
strategy = tf.distribute.experimental.TPUStrategy(resolver)

from tensorflow.keras.applications import ResNet152V2

with strategy.scope():
    factory = ModelFactory()

    model = factory.createPretrainedModel(ResNet152V2)

    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    history = model.fit(
        x_train_1, y_train_1, 
        validation_data = (x_test_1, y_test_1),
        batch_size=2048, 
        epochs=50,
        callbacks = [
            tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, restore_best_weights= True),
            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights= True)
        ]
    )

model.evaluate(x_test_1, y_test_1, 1024)

visualize_history(history)

"""### MobileNetV2"""

resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])
tf.config.experimental_connect_to_cluster(resolver)
tf.tpu.experimental.initialize_tpu_system(resolver)
strategy = tf.distribute.experimental.TPUStrategy(resolver)

from tensorflow.keras.applications import MobileNetV2

with strategy.scope():
    factory = ModelFactory()

    model = factory.createPretrainedModel(MobileNetV2)

    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    history = model.fit(
        x_train_1, y_train_1, 
        validation_data = (x_test_1, y_test_1),
        batch_size=2048, 
        epochs=50,
        callbacks = [
            tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, restore_best_weights= True),
            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights= True)
        ]
    )

model.evaluate(x_test_1, y_test_1, 1024)

visualize_history(history)

"""## Deep Neural Network Model"""

resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])
tf.config.experimental_connect_to_cluster(resolver)
tf.tpu.experimental.initialize_tpu_system(resolver)
strategy = tf.distribute.experimental.TPUStrategy(resolver)

with strategy.scope():
    factory = ModelFactory()

    model = factory.createPlainModel()

    model.compile(
        optimizer='adam',
        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
        metrics=['accuracy']
    )

    history = model.fit(
        x_train, y_train, 
        validation_data = (x_test, y_test),
        batch_size=2048, 
        epochs=50,
        callbacks = [
            tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, restore_best_weights= True),
            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights= True)
        ]
    )

model.evaluate(x_test, y_test, 1024)

visualize_history(history)

"""## Simple CNN Model"""

resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])
tf.config.experimental_connect_to_cluster(resolver)
tf.tpu.experimental.initialize_tpu_system(resolver)
strategy = tf.distribute.experimental.TPUStrategy(resolver)

with strategy.scope():
    factory = ModelFactory()

    model = factory.createSimpleCNNModel()

    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    history = model.fit(
        x_train_1, y_train_1, 
        validation_data = (x_test_1, y_test_1),
        batch_size=2048, 
        epochs=50,
        callbacks = [
            tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, restore_best_weights= True),
            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights= True)
        ]
    )

model.evaluate(x_test_1, y_test_1, 1024)

visualize_history(history)

"""## CNN Model 1"""

resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])
tf.config.experimental_connect_to_cluster(resolver)
tf.tpu.experimental.initialize_tpu_system(resolver)
strategy = tf.distribute.experimental.TPUStrategy(resolver)

with strategy.scope():
    factory = ModelFactory()

    model = factory.createCNNModel_1()

    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    history = model.fit(
        x_train_1, y_train_1, 
        validation_data = (x_test_1, y_test_1),
        batch_size=2048, 
        epochs=50,
        callbacks = [
            tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5, restore_best_weights= True),
            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights= True)
        ]
    )

model.evaluate(x_test_1, y_test_1, 1024)

visualize_history(history)

"""## CNN Model 2"""

resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])
tf.config.experimental_connect_to_cluster(resolver)
tf.tpu.experimental.initialize_tpu_system(resolver)
strategy = tf.distribute.experimental.TPUStrategy(resolver)

with strategy.scope():
    factory = ModelFactory()

    model = factory.createCNNModel_2()

    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    history = model.fit(
        x_train_1, y_train_1, 
        validation_data = (x_test_1, y_test_1),
        batch_size=2048, 
        epochs=50,
        callbacks = [
            tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5, restore_best_weights= True),
            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights= True)
        ]
    )

model.evaluate(x_test_1, y_test_1, 1024)

visualize_history(history)